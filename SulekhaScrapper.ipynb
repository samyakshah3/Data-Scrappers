{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ffabeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (119.0.6045.105) detected in PATH at C:\\Users\\ssamy\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe might not be compatible with the detected chrome version (120.0.6099.129); currently, chromedriver 120.0.6099.109 is recommended for chrome 120.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Inspired Overseas Janakpuri Delhi', 'Phone': 'tel:08048046332', 'Address': '701-702, Plot No. 10, Vishal Tower, District Centre, Janakpuri, Delhi - 110058', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'Mindways Consulting Nehru Place Delhi', 'Phone': 'tel:08069876334', 'Address': '1106, 11th Floor, Chiranjiv Tower 43, Nehru Place, Delhi - 110019', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'AB Educational Avenues Pvt. Ltd. Nehru Place Delhi', 'Phone': 'tel:08069873650', 'Address': 'No. 103, Chiranjivi Tower, Nehru Place, Delhi - 110019', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'Keemaya Overseas Education Services Dwarka Delhi', 'Phone': 'tel:08069876047', 'Address': 'No. D-484, 3rd Floor, Ramphal Chowk, Sec-7, Dwarka, Delhi - 110075', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'Academic & Professional Studies Abroad - APSA Sector 53 Gurgaon', 'Phone': 'tel:08069868522', 'Address': 'No. 1309, 13th Floor, Devika Tower 6, Nehru Place, Sector 53, Gurgaon - 122002', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'Jamboree Education Pvt. Ltd. New Friends Colony Delhi', 'Phone': 'tel:08035428028', 'Address': '7B/3, 4th Floor, Taimoor Nagar, Maharani Bagh, South Delhi__South, Delhi,Delhi - 110025, New Friends Colony, Delhi - 110025', 'Verified': 'Unverified', 'Premium': 'Premium'}\n",
      "{'Name': 'Kalpvriksh Overseas Education Consultants Sector 54 Gurgaon', 'Phone': 'tel:08069874116', 'Address': 'No 101E, Kalpvriksh 1st Floor, South Point Mall, Golf Course Road, Sector 54, Gurgaon - 122002', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'Glen Education Links Vaishali Sector 1 Ghaziabad', 'Phone': 'tel:08048093238', 'Address': 'Glen Education Links, 1/424 UG1 Max Hospital Road Near Allahabad Bank Vaishali Ghaziabad,Ghaziabad-201010', 'Verified': 'Unverified', 'Premium': 'Premium'}\n",
      "{'Name': 'AQG India Educonsultancy Private Limited Sector 18 Noida', 'Phone': 'tel:08035427008', 'Address': 'Comercial Unit No 701, 7th Floor, Wave Silver Tower, Plot No D-6, Sector 18, Noida - 201301', 'Verified': 'Verified', 'Premium': 'Premium'}\n",
      "{'Name': 'PI Overseas Private Limited Nehru Place Delhi', 'Phone': 'tel:08069869431', 'Address': '103/38, Ansal Tower, Nehru Place, Delhi - 110019', 'Verified': 'Verified', 'Premium': 'Premium'}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Specify the path to the ChromeDriver executable\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"executable_path=chromedriver.exe\")\n",
    "\n",
    "# Initialize the Chrome WebDriver with the options\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "url = 'https://www.sulekha.com/overseas-education-consultants/delhi'\n",
    "browser.get(url)\n",
    "\n",
    "fields = ['Name', 'Phone', 'Address', 'Verified', 'Premium']\n",
    "out_file = open('sulekha.csv', 'w', newline='', encoding='utf-8')  # Added newline and encoding\n",
    "csvwriter = csv.DictWriter(out_file, delimiter=',', fieldnames=fields)\n",
    "csvwriter.writeheader()  # Write the header row\n",
    "\n",
    "visited_entries = set()  # Initialize a set to track visited entries\n",
    "\n",
    "while True:\n",
    "    # Check for the presence of a pop-up\n",
    "    try:\n",
    "        close_button = browser.find_element(By.CLASS_NAME, 'close.filled svg')\n",
    "        if close_button:\n",
    "            # If the close button is found, click it using JavaScript\n",
    "            browser.execute_script(\"arguments[0].click();\", close_button)\n",
    "            time.sleep(2)  # Wait for the pop-up to close\n",
    "    except:\n",
    "        pass  # Ignore any exceptions related to pop-up handling\n",
    "\n",
    "    # Get the page source\n",
    "    source = browser.page_source\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    # Find all the <div> elements with class \"name\"\n",
    "    div_elements = soup.find_all('div', class_='name')\n",
    "\n",
    "    for div_element in div_elements:\n",
    "        # Extract the <a> element with the specific structure\n",
    "        a_element = div_element.find('a', href=True)\n",
    "\n",
    "        if a_element:\n",
    "            # Extract the href from the <a> element (relative path)\n",
    "            relative_url = a_element['href']\n",
    "\n",
    "            if relative_url not in visited_entries:\n",
    "                # If this entry has not been visited, scrape it\n",
    "                visited_entries.add(relative_url)\n",
    "\n",
    "                # Construct the absolute URL\n",
    "                new_tab_url = urljoin(url, relative_url)\n",
    "\n",
    "                # Open the new tab using JavaScript\n",
    "                browser.get(new_tab_url)\n",
    "\n",
    "                # Wait for the page to load (5 seconds)\n",
    "                time.sleep(5)\n",
    "\n",
    "                # Extract Name, Phone, and Address from the new tab\n",
    "                source = browser.page_source\n",
    "                soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "                name_element = soup.find('h1', class_='title-primary')\n",
    "                name = name_element.text if name_element else 'Name not found'\n",
    "\n",
    "                # Extract the phone number using the specific sulga attribute\n",
    "                phone_element = soup.find('a', href=True, sulga=\"Profile - Icon Click First Fold^Call Click^Call Button\")\n",
    "                phone = phone_element['href'] if phone_element else 'Phone not found'\n",
    "\n",
    "                # Extract the address using a specific condition\n",
    "                address_element = soup.select_one('.item .title-medium:-soup-contains(\"Address\") + p')\n",
    "                address = address_element.text if address_element else 'Address not found'\n",
    "\n",
    "                # Extract the SVG elements for \"Verified\" and \"Premium\" badges\n",
    "                verified_badge = soup.find('svg', class_='verified-tick')\n",
    "                premium_badge = soup.find('svg', class_='premium-badge')\n",
    "\n",
    "                # Check if the \"Verified\" badge is present\n",
    "                verified_status = 'Verified' if verified_badge else 'Unverified'\n",
    "\n",
    "                # Check if the \"Premium\" badge is present\n",
    "                premium_status = 'Premium' if premium_badge else 'N/A'\n",
    "\n",
    "                # Update the 'details' dictionary with the badge statuses\n",
    "                details = {'Name': name, 'Phone': phone, 'Address': address, 'Verified': verified_status, 'Premium': premium_status}\n",
    "\n",
    "                try:\n",
    "                    csvwriter.writerow(details)\n",
    "                    out_file.flush()  # Flush the data to the file\n",
    "                    print(details)\n",
    "                except:\n",
    "                    print('Error in writing')\n",
    "\n",
    "                # Click the back button to return to the original URL\n",
    "                browser.get(url)  # Go back to the original URL\n",
    "\n",
    "    # Check if there's a \"View More\" button to load more entries\n",
    "    view_more_button = browser.find_elements(By.XPATH, \"//span[@class='button line-primary medium' and @id='btnviewmorebiz']\")\n",
    "    if view_more_button:\n",
    "        view_more_button[0].click()\n",
    "        time.sleep(3)  # Wait for the next set of entries to load\n",
    "    else:\n",
    "        break  # No more entries, exit the loop\n",
    "\n",
    "out_file.close()  # Close the CSV file when done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787630d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
